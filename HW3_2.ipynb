{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dx35qSU4OJly",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import os\n",
        "import csv\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPsueHlvOuDi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GatedShortcutConnection(nn.Module):\n",
        "  def __init__(self, n_ch=64):\n",
        "    super().__init__()\n",
        "    self.convA = nn.Conv2d(n_ch * 2, n_ch * 2, 1)\n",
        "    self.convB = nn.Conv2d(n_ch * 2, n_ch * 2, 1)\n",
        "    self.sigm = nn.Sigmoid()\n",
        "\n",
        "  def forward(self, x):\n",
        "    A = self.convA(x)\n",
        "    B = self.convB(x)\n",
        "    z = A * self.sigm(B)\n",
        "    return z\n",
        "\n",
        "class ResidualStack(nn.Module):\n",
        "  def __init__(self, n_ch=64):\n",
        "    super().__init__()\n",
        "    self.layers = nn.ModuleList()\n",
        "    n_in_ch = n_ch * 4\n",
        "    for _ in range(5):\n",
        "      self.layers.append(nn.ReLU())\n",
        "      self.layers.append(nn.Conv2d(n_in_ch, n_ch, (3,3), (1,1)))\n",
        "      n_in_ch = n_ch * 2\n",
        "      self.layers.append(nn.ReLU())\n",
        "      self.layers.append(nn.Conv2d(n_ch, n_ch * 2, (3,3), (1,1)))\n",
        "      self.layers.append(nn.ReLU())\n",
        "      self.layers.append(GatedShortcutConnection())\n",
        "      self.layers.append(nn.ReLU())\n",
        "    self.relu = nn.ReLU()\n",
        "  \n",
        "  def forward(self, x):\n",
        "    z = self.layers(x)\n",
        "    z = self.relu(z)\n",
        "    return z"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0Jcaw4lQzLN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "61479519-106c-42c0-b83e-898728fd642f"
      },
      "source": [
        "ResidualStack()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResidualStack(\n",
              "  (layers): ModuleList(\n",
              "    (0): ReLU()\n",
              "    (1): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (2): ReLU()\n",
              "    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (4): ReLU()\n",
              "    (5): GatedShortcutConnection(\n",
              "      (convA): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (convB): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (sigm): Sigmoid()\n",
              "    )\n",
              "    (6): ReLU()\n",
              "    (7): ReLU()\n",
              "    (8): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (9): ReLU()\n",
              "    (10): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (11): ReLU()\n",
              "    (12): GatedShortcutConnection(\n",
              "      (convA): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (convB): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (sigm): Sigmoid()\n",
              "    )\n",
              "    (13): ReLU()\n",
              "    (14): ReLU()\n",
              "    (15): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (16): ReLU()\n",
              "    (17): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (18): ReLU()\n",
              "    (19): GatedShortcutConnection(\n",
              "      (convA): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (convB): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (sigm): Sigmoid()\n",
              "    )\n",
              "    (20): ReLU()\n",
              "    (21): ReLU()\n",
              "    (22): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (23): ReLU()\n",
              "    (24): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (25): ReLU()\n",
              "    (26): GatedShortcutConnection(\n",
              "      (convA): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (convB): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (sigm): Sigmoid()\n",
              "    )\n",
              "    (27): ReLU()\n",
              "    (28): ReLU()\n",
              "    (29): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (30): ReLU()\n",
              "    (31): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (32): ReLU()\n",
              "    (33): GatedShortcutConnection(\n",
              "      (convA): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (convB): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (sigm): Sigmoid()\n",
              "    )\n",
              "    (34): ReLU()\n",
              "  )\n",
              "  (relu): ReLU()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tC95KV9OQW4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class VAEEncoder(nn.Module):\n",
        "    def __init__(self, n_ch):\n",
        "        super().__init__()\n",
        "        self.layers = nn.ModuleList()\n",
        "        self.layers.append(nn.Conv2d(3, n_ch * 2, (4,4), (2,2)))\n",
        "        self.layers.append(nn.ReLU())\n",
        "        self.layers.append(nn.Conv2d(n_ch * 2, n_ch * 4, (4,4), (2,2)))\n",
        "        self.layers.append(nn.ReLU())\n",
        "        self.layers.append(nn.Conv2d(n_ch * 4, n_ch * 4, (3,3), (1,1)))\n",
        "        self.layers.append(ResidualStack())\n",
        "        \n",
        "    def encode(self, x, muf, sigmaf):\n",
        "        z = self.forward(x)\n",
        "        mu = muf(z)\n",
        "        sigma = sigmaf(z)\n",
        "        return mu, torch.exp(sigma)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        z = self.layers(x)\n",
        "        return z\n",
        "\n",
        "class VAEDecoder(nn.Module):\n",
        "    def __init__(self, n_ch):\n",
        "        super().__init__()\n",
        "        self.layers = nn.ModuleList()\n",
        "        self.layers.append(nn.Conv2d(n_ch * 2, n_ch * 4, (3,3), (1,1)))\n",
        "        self.layers.append(ResidualStack())\n",
        "        self.layers.append(nn.ConvTranspose2d(n_ch * 2, n_ch * 2, (4,4), (2,2)))\n",
        "        self.layers.append(nn.ReLU())\n",
        "        self.layers.append(nn.ConvTranspose2d(n_ch * 2, 6, (4,4), (2,2)))\n",
        "        \n",
        "    def encode(self, x, muf, sigmaf):\n",
        "        z = self.forward(x)\n",
        "        mu = muf(z)\n",
        "        sigma = sigmaf(z)\n",
        "        return mu, torch.exp(sigma)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        z = self.layers(x)\n",
        "        return z\n",
        "        \n",
        "class VAE(nn.Module):\n",
        "    def __init__(self, latd=2, ind=2, lin_dim=64):\n",
        "        super().__init__()\n",
        "        self.latd = latd\n",
        "        self.ind = ind\n",
        "        self.encoder = VAEEncoder(64)\n",
        "        self.decoder = VAEDecoder(64)\n",
        "        self.mu_encode = nn.Linear(lin_dim, ind)\n",
        "        self.mu_decode = nn.Linear(lin_dim, latd)\n",
        "        self.sigma_encode = nn.Linear(lin_dim, ind)\n",
        "        self.sigma_decode = nn.Linear(lin_dim, latd)\n",
        "        self.normd = torch.distributions.Normal(torch.tensor([0.0]), torch.tensor([1.0]))\n",
        "        \n",
        "    def sample(self, mu, sigma):\n",
        "        if not self.training:\n",
        "            return mu\n",
        "        standard = self.normd.sample(mu.shape).to(device).view(mu.shape)\n",
        "        return mu + standard * torch.sqrt(sigma)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        mu_z, sigma_z = self.encoder.encode(x, self.mu_encode, self.sigma_encode)\n",
        "        z = self.sample(mu_z, sigma_z)\n",
        "        mu_x, sigma_x = self.decoder.decode(z, self.mu_decode, self.sigma_decode)\n",
        "        return mu_z, sigma_z, mu_x, sigma_x\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MywUbR8FVNHQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "30b9fedf-a53f-4bfc-9058-ebe980eb7c0b"
      },
      "source": [
        "VAE()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VAE(\n",
              "  (encoder): VAEEncoder(\n",
              "    (layers): ModuleList(\n",
              "      (0): Conv2d(3, 128, kernel_size=(4, 4), stride=(2, 2))\n",
              "      (1): ReLU()\n",
              "      (2): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2))\n",
              "      (3): ReLU()\n",
              "      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
              "      (5): ResidualStack(\n",
              "        (layers): ModuleList(\n",
              "          (0): ReLU()\n",
              "          (1): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "          (2): ReLU()\n",
              "          (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
              "          (4): ReLU()\n",
              "          (5): GatedShortcutConnection(\n",
              "            (convA): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (convB): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (sigm): Sigmoid()\n",
              "          )\n",
              "          (6): ReLU()\n",
              "          (7): ReLU()\n",
              "          (8): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "          (9): ReLU()\n",
              "          (10): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
              "          (11): ReLU()\n",
              "          (12): GatedShortcutConnection(\n",
              "            (convA): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (convB): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (sigm): Sigmoid()\n",
              "          )\n",
              "          (13): ReLU()\n",
              "          (14): ReLU()\n",
              "          (15): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "          (16): ReLU()\n",
              "          (17): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
              "          (18): ReLU()\n",
              "          (19): GatedShortcutConnection(\n",
              "            (convA): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (convB): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (sigm): Sigmoid()\n",
              "          )\n",
              "          (20): ReLU()\n",
              "          (21): ReLU()\n",
              "          (22): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "          (23): ReLU()\n",
              "          (24): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
              "          (25): ReLU()\n",
              "          (26): GatedShortcutConnection(\n",
              "            (convA): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (convB): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (sigm): Sigmoid()\n",
              "          )\n",
              "          (27): ReLU()\n",
              "          (28): ReLU()\n",
              "          (29): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "          (30): ReLU()\n",
              "          (31): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
              "          (32): ReLU()\n",
              "          (33): GatedShortcutConnection(\n",
              "            (convA): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (convB): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (sigm): Sigmoid()\n",
              "          )\n",
              "          (34): ReLU()\n",
              "        )\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (decoder): VAEDecoder(\n",
              "    (layers): ModuleList(\n",
              "      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
              "      (1): ResidualStack(\n",
              "        (layers): ModuleList(\n",
              "          (0): ReLU()\n",
              "          (1): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "          (2): ReLU()\n",
              "          (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
              "          (4): ReLU()\n",
              "          (5): GatedShortcutConnection(\n",
              "            (convA): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (convB): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (sigm): Sigmoid()\n",
              "          )\n",
              "          (6): ReLU()\n",
              "          (7): ReLU()\n",
              "          (8): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "          (9): ReLU()\n",
              "          (10): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
              "          (11): ReLU()\n",
              "          (12): GatedShortcutConnection(\n",
              "            (convA): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (convB): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (sigm): Sigmoid()\n",
              "          )\n",
              "          (13): ReLU()\n",
              "          (14): ReLU()\n",
              "          (15): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "          (16): ReLU()\n",
              "          (17): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
              "          (18): ReLU()\n",
              "          (19): GatedShortcutConnection(\n",
              "            (convA): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (convB): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (sigm): Sigmoid()\n",
              "          )\n",
              "          (20): ReLU()\n",
              "          (21): ReLU()\n",
              "          (22): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "          (23): ReLU()\n",
              "          (24): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
              "          (25): ReLU()\n",
              "          (26): GatedShortcutConnection(\n",
              "            (convA): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (convB): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (sigm): Sigmoid()\n",
              "          )\n",
              "          (27): ReLU()\n",
              "          (28): ReLU()\n",
              "          (29): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "          (30): ReLU()\n",
              "          (31): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
              "          (32): ReLU()\n",
              "          (33): GatedShortcutConnection(\n",
              "            (convA): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (convB): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (sigm): Sigmoid()\n",
              "          )\n",
              "          (34): ReLU()\n",
              "        )\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (2): ConvTranspose2d(128, 128, kernel_size=(4, 4), stride=(2, 2))\n",
              "      (3): ReLU()\n",
              "      (4): ConvTranspose2d(128, 6, kernel_size=(4, 4), stride=(2, 2))\n",
              "    )\n",
              "  )\n",
              "  (mu_encode): Linear(in_features=64, out_features=2, bias=True)\n",
              "  (mu_decode): Linear(in_features=64, out_features=2, bias=True)\n",
              "  (sigma_encode): Linear(in_features=64, out_features=2, bias=True)\n",
              "  (sigma_decode): Linear(in_features=64, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmovZzxKVVnB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}